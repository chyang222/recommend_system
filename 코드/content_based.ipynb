{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adjusting for Data Frame Output\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read BX-Book-Ratings.csv\n",
    "origin_rating = pd.read_csv('dataset/Book reviews/Book reviews/BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "origin_rating.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1031175 entries, 0 to 1031174\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   Unnamed: 0           1031175 non-null  int64  \n",
      " 1   user_id              1031175 non-null  int64  \n",
      " 2   location             1031175 non-null  object \n",
      " 3   age                  1031175 non-null  float64\n",
      " 4   isbn                 1031175 non-null  object \n",
      " 5   rating               1031175 non-null  int64  \n",
      " 6   book_title           1031175 non-null  object \n",
      " 7   book_author          1031175 non-null  object \n",
      " 8   year_of_publication  1031175 non-null  float64\n",
      " 9   publisher            1031175 non-null  object \n",
      " 10  img_s                1031175 non-null  object \n",
      " 11  img_m                1031175 non-null  object \n",
      " 12  img_l                1031175 non-null  object \n",
      " 13  Summary              1031175 non-null  object \n",
      " 14  Language             1031175 non-null  object \n",
      " 15  Category             1031175 non-null  object \n",
      " 16  city                 1017072 non-null  object \n",
      " 17  state                1008377 non-null  object \n",
      " 18  country              995801 non-null   object \n",
      "dtypes: float64(2), int64(3), object(14)\n",
      "memory usage: 149.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read Preprocessed_data.csv\n",
    "origin_preprocessed = pd.read_csv(\n",
    "    'dataset/Books Data with Category Language and Summary/Preprocessed_data.csv', sep=',', encoding=\"latin-1\")\n",
    "origin_preprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270170 entries, 0 to 1031174\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Book-Title  270170 non-null  object\n",
      " 1   ISBN        270170 non-null  object\n",
      " 2   Category    270170 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "origin_preprocessed = origin_preprocessed.loc[:, ['book_title', 'isbn', 'Category']]\n",
    "origin_preprocessed.rename(columns={'book_title': 'Book-Title'}, inplace=True)\n",
    "origin_preprocessed.rename(columns={'isbn': 'ISBN'}, inplace=True)\n",
    "origin_preprocessed.drop_duplicates(['ISBN'], inplace=True)\n",
    "origin_preprocessed.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1031175 entries, 0 to 1031174\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1031175 non-null  int64 \n",
      " 1   ISBN         1031175 non-null  object\n",
      " 2   Book-Rating  1031175 non-null  int64 \n",
      " 3   Book-Title   1031175 non-null  object\n",
      " 4   Category     1031175 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 47.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge 'origin_preprocessed' data and 'origin_rating' data about ISBN\n",
    "user_book_rating = pd.merge(origin_rating, origin_preprocessed, on=\"ISBN\")\n",
    "user_book_rating.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null data\n",
    "user_book_rating.isnull().sum()\n",
    "\n",
    "# drop null data\n",
    "user_book_rating.dropna(inplace=True)\n",
    "\n",
    "# change data type\n",
    "user_book_rating['Book-Rating'] = user_book_rating['Book-Rating'].astype(float)\n",
    "\n",
    "# Rating average\n",
    "avg_ratings = user_book_rating.groupby('ISBN', as_index=False)['Book-Rating'].mean()\n",
    "avg_ratings = avg_ratings.rename(columns={'Book-Rating': 'Average-Rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 234876 entries, 0 to 710818\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   User-ID      234876 non-null  int64  \n",
      " 1   ISBN         234876 non-null  object \n",
      " 2   Book-Rating  234876 non-null  float64\n",
      " 3   Book-Title   234876 non-null  object \n",
      " 4   Category     234876 non-null  object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate rating count each ISBN\n",
    "book_ratingCount = (user_book_rating.groupby(by=['ISBN'])\n",
    "                    ['Book-Rating'].\n",
    "                    count().\n",
    "                    reset_index().\n",
    "                    rename(columns={'Book-Rating': 'TotalRatingCount'})\n",
    "                    )\n",
    "\n",
    "user_book_rating = pd.merge(user_book_rating, book_ratingCount, on=\"ISBN\")\n",
    "\n",
    "# Delete data about rating count under 50\n",
    "ratingThreshold = 50\n",
    "user_book_rating = user_book_rating.query('TotalRatingCount >= @ratingThreshold')\n",
    "user_book_rating.drop(columns='TotalRatingCount', inplace=True)\n",
    "user_book_rating.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing 'Category' column\n",
    "pre_dataframe = user_book_rating.copy()\n",
    "pre_dataframe = pre_dataframe.drop(columns=['User-ID', 'Book-Rating'])\n",
    "pre_dataframe = pd.merge(pre_dataframe, avg_ratings, on='ISBN')\n",
    "\n",
    "# delete special symbols\n",
    "pre_dataframe[\"Category\"] = pre_dataframe[\"Category\"].str.replace(\n",
    "    pat=r'[^\\w]', repl=r' ', regex=True)\n",
    "pre_dataframe[\"Category\"] = pre_dataframe[\"Category\"].str.lower()\n",
    "\n",
    "# Strange category value '9' delete\n",
    "delete = pre_dataframe[pre_dataframe['Category'] == '9'].index\n",
    "pre_dataframe.drop(delete, inplace=True)\n",
    "\n",
    "# delete duplicate entries\n",
    "pre_dataframe = pre_dataframe.drop_duplicates(['ISBN'])\n",
    "pre_dataframe = pre_dataframe.reset_index(drop=True)\n",
    "\n",
    "# Extract Category data\n",
    "category = list(pre_dataframe['Category'].to_list())\n",
    "\n",
    "# Extract User-ID data\n",
    "isbn = list(set(pre_dataframe['ISBN'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Data Modeling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'fiction': 15,\n 'juvenile': 24,\n 'business': 6,\n 'economics': 12,\n 'humor': 21,\n 'history': 20,\n 'biography': 4,\n 'autobiography': 3,\n 'american': 1,\n 'family': 14,\n 'relationships': 28,\n 'fictitious': 16,\n 'character': 8,\n 'religion': 29,\n 'intelligence': 23,\n 'california': 7,\n 'domestic': 10,\n 'body': 5,\n 'mind': 26,\n 'spirit': 31,\n 'self': 30,\n 'help': 19,\n 'literary': 25,\n 'true': 33,\n 'crime': 9,\n 'african': 0,\n 'england': 13,\n 'health': 18,\n 'fitness': 17,\n 'americans': 2,\n 'dune': 11,\n 'imaginary': 22,\n 'place': 27,\n 'travel': 32}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df=3, stop_words='english')\n",
    "transformed_weights = vect.fit_transform(pre_dataframe['Category'])\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            african  american  americans  autobiography  biography  body  \\\n034545104X      0.0       0.0        0.0            0.0        0.0   0.0   \n0449006522      0.0       0.0        0.0            0.0        0.0   0.0   \n0553561618      0.0       0.0        0.0            0.0        0.0   0.0   \n055356451X      0.0       0.0        0.0            0.0        0.0   0.0   \n0060517794      0.0       0.0        0.0            0.0        0.0   0.0   \n...             ...       ...        ...            ...        ...   ...   \n0449002411      0.0       0.0        0.0            0.0        0.0   0.0   \n044023512X      0.0       0.0        0.0            0.0        0.0   0.0   \n0345450728      0.0       0.0        0.0            0.0        0.0   0.0   \n0385720114      0.0       0.0        0.0            0.0        0.0   0.0   \n0451180216      0.0       0.0        0.0            0.0        0.0   0.0   \n\n            business  california  character  crime  domestic  dune  economics  \\\n034545104X       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0449006522       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0553561618       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n055356451X       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0060517794       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n...              ...         ...        ...    ...       ...   ...        ...   \n0449002411       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n044023512X       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0345450728       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0385720114       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n0451180216       0.0         0.0        0.0    0.0       0.0   0.0        0.0   \n\n            england  family  fiction  fictitious  fitness  health  help  \\\n034545104X      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0449006522      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0553561618      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n055356451X      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0060517794      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n...             ...     ...      ...         ...      ...     ...   ...   \n0449002411      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n044023512X      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0345450728      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0385720114      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n0451180216      0.0     0.0      1.0         0.0      0.0     0.0   0.0   \n\n            history  humor  imaginary  intelligence  juvenile  literary  mind  \\\n034545104X      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0449006522      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0553561618      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n055356451X      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0060517794      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n...             ...    ...        ...           ...       ...       ...   ...   \n0449002411      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n044023512X      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0345450728      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0385720114      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n0451180216      0.0    0.0        0.0           0.0       0.0       0.0   0.0   \n\n            place  relationships  religion  self  spirit  travel  true  \n034545104X    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0449006522    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0553561618    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n055356451X    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0060517794    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n...           ...            ...       ...   ...     ...     ...   ...  \n0449002411    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n044023512X    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0345450728    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0385720114    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n0451180216    0.0            0.0       0.0   0.0     0.0     0.0   0.0  \n\n[1452 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>african</th>\n      <th>american</th>\n      <th>americans</th>\n      <th>autobiography</th>\n      <th>biography</th>\n      <th>body</th>\n      <th>business</th>\n      <th>california</th>\n      <th>character</th>\n      <th>crime</th>\n      <th>domestic</th>\n      <th>dune</th>\n      <th>economics</th>\n      <th>england</th>\n      <th>family</th>\n      <th>fiction</th>\n      <th>fictitious</th>\n      <th>fitness</th>\n      <th>health</th>\n      <th>help</th>\n      <th>history</th>\n      <th>humor</th>\n      <th>imaginary</th>\n      <th>intelligence</th>\n      <th>juvenile</th>\n      <th>literary</th>\n      <th>mind</th>\n      <th>place</th>\n      <th>relationships</th>\n      <th>religion</th>\n      <th>self</th>\n      <th>spirit</th>\n      <th>travel</th>\n      <th>true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>034545104X</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0449006522</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0553561618</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>055356451X</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0060517794</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0449002411</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>044023512X</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0345450728</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0385720114</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0451180216</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1452 rows Ã— 34 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_df = pd.DataFrame(transformed_weights.toarray(), columns=vect.get_feature_names_out(),\n",
    "                            index=pre_dataframe['ISBN'].tolist())\n",
    "attribute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity (query, documents)\n",
    "similarity = cosine_similarity(transformed_weights, transformed_weights)\n",
    "\n",
    "# Construct a reverse map of indices and book title.\n",
    "indices_code = pd.Series(pre_dataframe.index,\n",
    "                         index=pre_dataframe['Book-Title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(book_title, cosine_sim, data_info):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices_code[book_title]\n",
    "\n",
    "    # Similarity scores\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the six most similar books\n",
    "    similarity_scores = similarity_scores[0:10]\n",
    "\n",
    "    # Get the book indices\n",
    "    book_indices = [i[0] for i in similarity_scores]\n",
    "\n",
    "    tmp = (data_info.iloc[book_indices]).sort_values(by='Average-Rating', ascending=False)\n",
    "\n",
    "    same = tmp[tmp['Book-Title'] == book_title].index\n",
    "    tmp.drop(same, inplace=True)\n",
    "\n",
    "    # Return the top 5 most similar books\n",
    "    return tmp['Book-Title'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book list\n"
     ]
    },
    {
     "data": {
      "text/plain": "0           Flesh Tones: A Novel\n1            Manhattan Hunt Club\n2                  Dark Paradise\n3                     Night Sins\n4       Little Altars Everywhere\n                  ...           \n1447                The Presence\n1448               City of Light\n1449              Distant Shores\n1450             The Map of Love\n1451         Interest of Justice\nName: Book-Title, Length: 1452, dtype: object"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Book list')\n",
    "pre_dataframe['Book-Title']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10                      Bridget Jones's Diary\n4                    Little Altars Everywhere\n6     The Girl Who Loved Tom Gordon : A Novel\n1                         Manhattan Hunt Club\n8                               The Dark Half\nName: Book-Title, dtype: object"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Wild Animus', similarity, pre_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "32     Harry Potter and the Chamber of Secrets (Book 2)\n9     Harry Potter and the Order of the Phoenix (Boo...\n33    Harry Potter and the Sorcerer's Stone (Harry P...\n13                                    A Wrinkle In Time\n31                                             Coraline\nName: Book-Title, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Walk Two Moons\", similarity, pre_dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6602f6cc7e8435aa3476c36f824188212d0c07606c2c4831879390ff4ab627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}